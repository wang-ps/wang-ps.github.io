<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="keywords" content="Pengshuai Wang, Peng-Shuai Wang, MSRA, Tsinghua University, 王鹏帅, 清华大学, unsupervised pretrain, multi-resolution instance discrimination, O-CNN">
<meta name="description" content="	Unsupervised 3D Learning for Shape Analysis via Multiresolution Instance Discrimination">
<link rel="stylesheet" href="./Pengshuai Wang - Homepage_files/style/jemdoc.css" type="text/css">
<style type="text/css">
</style>
<title>Pretrain3D</title>
<link rel="shortcut icon" href="./Pengshuai Wang - Homepage_files/img/favicon.ico" >
<!--link rel="shortcut icon" type="image/gif" href="./Pengshuai Wang - Homepage_files/img/animated_favicon1.gif" -->
</head>


<body>
<div id="layout-content" style="margin-top:25px">

<!-- teaser -->
<table border="0" width="100%"> <tbody>
<tr>
  <td valign="top" align="center">
    <b><font size="5" face="Times New Roman" >Unsupervised 3D Learning for Shape Analysis via Multiresolution Instance Discrimination</font></b>
    <br><br>
  </td>
</tr>

<tr>
  <td valign="top" align="center">
    <font size="4" face="Times New Roman" > <a href="https://wang-ps.github.io/"  target="_blank">Peng-Shuai Wang</a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
    <font size="4" face="Times New Roman" >Yu-Qi Yang </font> <font size="2"><sup>21</sup></font> &emsp;&emsp;
    <font size="4" face="Times New Roman" >Qian-Fang Zou </font> <font size="2"><sup>31</sup></font> &emsp;&emsp;
    <font size="4" face="Times New Roman" > <a href="https://www.microsoft.com/en-us/research/people/wuzhiron/" target="_blank"> Zhirong Wu </a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
    <font size="4" face="Times New Roman" > <a href="https://xueyuhanlang.github.io/"  target="_blank">Yang Liu</a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
    <font size="4" face="Times New Roman" > <a href="http://research.microsoft.com/en-us/um/people/xtong/xtong.html"  target="_blank">Xin Tong</a> </font> <font size="2"><sup>1</sup></font>
    <br>
    <font size="2"> <sup>1</sup></font> <font size="3" face="Times New Roman" ><a href="http://research.microsoft.com/en-us/labs/asia/" target="_blank">Microsoft Research Asia</a> </font>  &emsp;&emsp;
    <font size="2"> <sup>2</sup></font> <font size="3" face="Times New Roman" > <a href="http://www.tsinghua.edu.cn/" target="_blank">Tsinghua University</a></font> &emsp;&emsp;
    <font size="2"> <sup>3</sup></font> <font size="3" face="Times New Roman" > <a href="http://www.tsinghua.edu.cn/" target="_blank">University of Science and Technology of China </a></font>

    <br>
    <font size="3" face="Times New Roman" > AAAI Conference on Artificial Intelligence (AAAI), 2021 </font>
    <br> <br>
  </td>
</tr>

<tr>
  <td valign="top" align="center">
      <img width="100%" src="./pretrain_files/teaser.png">
  </td>
</tr>
</tbody> </table>

<!-- Abstract -->
<table border="0" width="100%"> <tbody>
<tr>
  <h2>Abstract</h2>
</tr>

<tr>
  <p style="text-align:justify;">
  <font face="Times New Roman" >
We propose an unsupervised method for learning a generic and efficient shape encoding network for different shape analysis tasks. Our key idea is to jointly encode and learn shape and point features from unlabeled 3D point clouds. For this purpose, we adapt HRNet to octree-based convolutional neural networks for jointly encoding shape and point features with fused multiresolution subnetworks and design a simple-yet-efficient Multiresolution Instance Discrimination (MID) loss for jointly learning the shape and point features. Our network takes a 3D point cloud as input and output both shape and point features. After training, Our network is concatenated with simple task-specific back-ends and fine-tuned for different shape analysis tasks. We evaluate the efficacy and generality of our method with a set of shape analysis tasks, including shape classification, semantic shape segmentation, as well as shape registration tasks. With simple back-ends, our network demonstrates the best performance among all unsupervised methods and achieves competitive performance to supervised methods. For fine-grained shape segmentation on the PartNet dataset, our method even surpasses existing supervised methods by a large margin.
  </font>
  </p>
</tr>

<tr>
  <td align="center" width="25%">
    <img src="./pretrain_files/thumbmail.png" width="210">
  </td>
  <td>
    <strong>Paper</strong> [<a href="https://arxiv.org/abs/2008.01068" target="_blank">PDF</a>] <br><br>
    <strong>Slides</strong> [<a href="https://1drv.ms/p/s!Ar9egoTYLACXkDcFFlwW_ze7B9Wi?e=eOrQeU" target="_blank">PPTX</a>] <br><br>
    <strong>Code&nbsp;&nbsp;</strong> [<a href="https://github.com/microsoft/O-CNN/blob/master/docs/unsupervised.md" target="_blank">Github</a>] <br><br>
    <strong>Citation</strong> [<a href="pretrain_files/pretrain3d.bib" target="_blank">BibTeX</a>]<br>
    <p style="text-align:justify;">
    <font face="Times New Roman" >
    Peng-Shuai Wang, Yu-Qi Yang, Qian-Fang Zou, Zhirong Wu, Yang Liu, and Xin Tong. 2020. Unsupervised 3D Learning for Shape Analysis via Multiresolution Instance Discrimination Analysis. In AAAI Conference on Artificial Intelligence (AAAI).
    </font>
    </p>
  </td>
</tr>
</tbody> </table>

</div>
</body>
</html>